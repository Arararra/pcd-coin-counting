{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasifikasi Koin Rupiah - Versi Diperbaiki & Optimized\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from skimage.feature import hog\n",
    "\n",
    "# =============================================\n",
    "# 1. EKSTRAKSI FITUR (KONSISTEN)\n",
    "# =============================================\n",
    "def extract_features(img):\n",
    "    \"\"\"\n",
    "    Ekstraksi fitur dari gambar koin dengan fitur tambahan untuk membedakan nominal\n",
    "    Returns: features vector, gray image, threshold image\n",
    "    \"\"\"\n",
    "    # Resize dulu untuk konsistensi\n",
    "    img_resized = cv2.resize(img, (128, 128))\n",
    "    \n",
    "    # Grayscale\n",
    "    if len(img_resized.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img_resized\n",
    "    \n",
    "    # Preprocessing dengan CLAHE untuk meningkatkan kontras\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray_clahe = clahe.apply(gray)\n",
    "    \n",
    "    # Otsu threshold\n",
    "    _, th = cv2.threshold(\n",
    "        gray_clahe, 0, 255,\n",
    "        cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "    \n",
    "    # HOG features dari threshold image\n",
    "    hog_feat = hog(\n",
    "        th,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm='L2-Hys'\n",
    "    )\n",
    "    \n",
    "    # HOG features dari grayscale (lebih detail)\n",
    "    hog_feat_gray = hog(\n",
    "        gray_clahe,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm='L2-Hys'\n",
    "    )\n",
    "    \n",
    "    # Hu Moments (Shape descriptor)\n",
    "    moments = cv2.moments(th)\n",
    "    hu_moments = cv2.HuMoments(moments)\n",
    "    hu_feat = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + 1e-10)\n",
    "    hu_feat = hu_feat.flatten()\n",
    "    \n",
    "    # Global statistics\n",
    "    white_ratio = np.sum(th == 255) / th.size\n",
    "    black_ratio = np.sum(th == 0) / th.size\n",
    "    mean_intensity = np.mean(gray_clahe)\n",
    "    std_intensity = np.std(gray_clahe)\n",
    "    \n",
    "    # Texture features menggunakan histogram\n",
    "    hist = cv2.calcHist([gray_clahe], [0], None, [16], [0, 256])\n",
    "    hist = hist.flatten() / hist.sum()  # Normalize\n",
    "    \n",
    "    # Central patch (area angka) - PENTING untuk membedakan nominal\n",
    "    h, w = gray_clahe.shape\n",
    "    \n",
    "    # Patch tengah (area angka)\n",
    "    center_patch = gray_clahe[int(h*0.4):int(h*0.75), int(w*0.3):int(w*0.7)]\n",
    "    \n",
    "    if center_patch.size > 0:\n",
    "        edges_center = cv2.Canny(center_patch, 50, 150)\n",
    "        edge_density_center = np.sum(edges_center > 0) / edges_center.size\n",
    "        center_mean = np.mean(center_patch)\n",
    "        center_std = np.std(center_patch)\n",
    "    else:\n",
    "        edge_density_center = 0\n",
    "        center_mean = 0\n",
    "        center_std = 0\n",
    "    \n",
    "    # Bottom patch (untuk nominal di bawah)\n",
    "    bottom_patch = gray_clahe[int(h*0.6):int(h*0.9), int(w*0.25):int(w*0.75)]\n",
    "    \n",
    "    if bottom_patch.size > 0:\n",
    "        edges_bottom = cv2.Canny(bottom_patch, 50, 150)\n",
    "        edge_density_bottom = np.sum(edges_bottom > 0) / edges_bottom.size\n",
    "    else:\n",
    "        edge_density_bottom = 0\n",
    "    \n",
    "    # Radius analysis (untuk membedakan ukuran koin)\n",
    "    contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) > 0:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        area = cv2.contourArea(largest_contour)\n",
    "        perimeter = cv2.arcLength(largest_contour, True)\n",
    "        \n",
    "        if perimeter > 0:\n",
    "            circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
    "        else:\n",
    "            circularity = 0\n",
    "    else:\n",
    "        area = 0\n",
    "        perimeter = 0\n",
    "        circularity = 0\n",
    "    \n",
    "    # Gabungkan semua fitur\n",
    "    features = np.hstack([\n",
    "        hog_feat,\n",
    "        hog_feat_gray,\n",
    "        hu_feat,\n",
    "        hist,\n",
    "        white_ratio,\n",
    "        black_ratio,\n",
    "        mean_intensity,\n",
    "        std_intensity,\n",
    "        edge_density_center,\n",
    "        edge_density_bottom,\n",
    "        center_mean,\n",
    "        center_std,\n",
    "        area,\n",
    "        perimeter,\n",
    "        circularity\n",
    "    ])\n",
    "    \n",
    "    return features, gray, th\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 2. LOAD DATASET\n",
    "# =============================================\n",
    "def load_dataset(dataset_path, use_side=False):\n",
    "    \"\"\"\n",
    "    Load dataset koin\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path ke folder dataset\n",
    "        use_side: True = klasifikasi depan/belakang, False = hanya nominal\n",
    "    \n",
    "    Returns:\n",
    "        X: feature array\n",
    "        y: label array\n",
    "        label_map: mapping label ke nama kelas\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Definisi kelas\n",
    "    CLASSES = [\"100_depan\", \"100_belakang\",\n",
    "               \"200_depan\", \"200_belakang\",\n",
    "               \"500_depan\", \"500_belakang\",\n",
    "               \"1000_depan\", \"1000_belakang\"]\n",
    "    \n",
    "    for label in CLASSES:\n",
    "        folder = os.path.join(dataset_path, label)\n",
    "        if not os.path.isdir(folder):\n",
    "            print(f\"Warning: Folder {folder} tidak ditemukan\")\n",
    "            continue\n",
    "        \n",
    "        files = os.listdir(folder)\n",
    "        print(f\"Loading {label}: {len(files)} images\")\n",
    "        \n",
    "        for file in files:\n",
    "            img_path = os.path.join(folder, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"Warning: Gagal membaca {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                features, _, _ = extract_features(img)\n",
    "                X.append(features)\n",
    "                \n",
    "                # Jika use_side=False, ambil hanya nominal\n",
    "                if not use_side:\n",
    "                    y.append(label.split('_')[0])  # \"100_depan\" -> \"100\"\n",
    "                else:\n",
    "                    y.append(label)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Buat label mapping\n",
    "    unique_labels = sorted(list(set(y)))\n",
    "    label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "    \n",
    "    print(f\"\\nTotal data loaded: {len(X)}\")\n",
    "    print(f\"Classes: {unique_labels}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    for label in unique_labels:\n",
    "        count = np.sum(y == label)\n",
    "        print(f\"  {label}: {count} samples\")\n",
    "    \n",
    "    return X, y, label_map\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 3. TRAINING MODEL (OPTIMIZED)\n",
    "# =============================================\n",
    "def train_model(X_train, y_train, X_val=None, y_val=None, fast_mode=True):\n",
    "    \"\"\"\n",
    "    Training SVM classifier dengan GridSearch\n",
    "    \n",
    "    Args:\n",
    "        fast_mode: True = parameter lebih sedikit (cepat), False = extensive search (akurat)\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm\", SVC(random_state=42, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    if fast_mode:\n",
    "        # FAST MODE: Parameter lebih sedikit (< 2 menit)\n",
    "        param_grid = {\n",
    "            \"svm__C\": [1, 10, 100],\n",
    "            \"svm__gamma\": [\"scale\", 0.01],\n",
    "            \"svm__kernel\": [\"rbf\"]  # Hanya RBF (paling umum untuk koin)\n",
    "        }\n",
    "        cv_folds = 3\n",
    "    else:\n",
    "        # EXTENSIVE MODE: Parameter lengkap (8+ menit)\n",
    "        param_grid = {\n",
    "            \"svm__C\": [0.1, 1, 10, 100, 1000],\n",
    "            \"svm__gamma\": [\"scale\", \"auto\", 0.1, 0.01, 0.001],\n",
    "            \"svm__kernel\": [\"rbf\", \"poly\", \"linear\"]\n",
    "        }\n",
    "        cv_folds = 5\n",
    "    \n",
    "    total_combinations = len(param_grid['svm__C']) * len(param_grid['svm__gamma']) * len(param_grid['svm__kernel'])\n",
    "    \n",
    "    print(\"\\nTraining model dengan GridSearchCV...\")\n",
    "    print(f\"Mode: {'FAST' if fast_mode else 'EXTENSIVE'}\")\n",
    "    print(f\"Total kombinasi parameter: {total_combinations}\")\n",
    "    print(f\"CV folds: {cv_folds}\")\n",
    "    print(f\"Estimasi waktu: {'< 2 menit' if fast_mode else '8+ menit'}\")\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=cv_folds,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    grid.fit(X_train, y_train)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training selesai dalam {elapsed_time:.1f} detik ({elapsed_time/60:.1f} menit)\")\n",
    "    print(f\"Best parameters: {grid.best_params_}\")\n",
    "    print(f\"Best CV score: {grid.best_score_:.3f}\")\n",
    "    \n",
    "    # Evaluasi di validation set jika ada\n",
    "    if X_val is not None and y_val is not None:\n",
    "        val_score = grid.score(X_val, y_val)\n",
    "        print(f\"Validation accuracy: {val_score:.3f}\")\n",
    "    \n",
    "    return grid.best_estimator_\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 4. EVALUASI MODEL\n",
    "# =============================================\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluasi model dan tampilkan metrics\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CONFUSION MATRIX\")\n",
    "    print(\"=\"*50)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Visualisasi confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    classes = sorted(list(set(y_test)))\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # Tambahkan angka di setiap cell\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 5. DETEKSI DAN PREDIKSI MULTIPLE COINS\n",
    "# =============================================\n",
    "def detect_and_predict(image, model, show_confidence=True):\n",
    "    \"\"\"\n",
    "    Deteksi dan klasifikasi multiple coins dalam satu gambar\n",
    "    \"\"\"\n",
    "    output = image.copy()\n",
    "    results = []\n",
    "    \n",
    "    # Preprocessing\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (9, 9), 2)\n",
    "    \n",
    "    # Otsu threshold\n",
    "    _, th = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Invert jika background terang\n",
    "    if np.mean(th) > 127:\n",
    "        th = cv2.bitwise_not(th)\n",
    "    \n",
    "    # Morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel)\n",
    "    th = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        return output, []\n",
    "    \n",
    "    # Process each contour\n",
    "    for i, c in enumerate(contours):\n",
    "        area = cv2.contourArea(c)\n",
    "        \n",
    "        if area < 3000:\n",
    "            continue\n",
    "        \n",
    "        # Get bounding circle\n",
    "        (x, y), r = cv2.minEnclosingCircle(c)\n",
    "        x, y, r = int(x), int(y), int(r)\n",
    "        \n",
    "        # Extract ROI dengan padding\n",
    "        padding = 10\n",
    "        y1 = max(0, y - r - padding)\n",
    "        y2 = min(image.shape[0], y + r + padding)\n",
    "        x1 = max(0, x - r - padding)\n",
    "        x2 = min(image.shape[1], x + r + padding)\n",
    "        \n",
    "        roi = image[y1:y2, x1:x2]\n",
    "        \n",
    "        if roi.size == 0 or roi.shape[0] < 50 or roi.shape[1] < 50:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Extract features dan prediksi\n",
    "            features, gray_roi, th_roi = extract_features(roi)\n",
    "            pred = model.predict([features])[0]\n",
    "            \n",
    "            # Get confidence scores\n",
    "            if hasattr(model.named_steps['svm'], 'decision_function'):\n",
    "                decision_scores = model.decision_function([features])[0]\n",
    "                confidence_scores = np.exp(decision_scores) / np.sum(np.exp(decision_scores))\n",
    "                classes = model.classes_\n",
    "                \n",
    "                pred_idx = np.where(classes == pred)[0][0]\n",
    "                confidence = confidence_scores[pred_idx]\n",
    "            else:\n",
    "                confidence = 1.0\n",
    "                confidence_scores = None\n",
    "                classes = None\n",
    "            \n",
    "            # Visualisasi\n",
    "            color = (0, 255, 0)  # Green\n",
    "            \n",
    "            if show_confidence and confidence < 0.5:\n",
    "                color = (0, 165, 255)  # Orange untuk low confidence\n",
    "            \n",
    "            cv2.circle(output, (x, y), r, color, 3)\n",
    "            \n",
    "            # Label dengan background\n",
    "            if show_confidence:\n",
    "                label = f\"Rp {pred} ({confidence*100:.0f}%)\"\n",
    "            else:\n",
    "                label = f\"Rp {pred}\"\n",
    "            \n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 1.0\n",
    "            thickness = 2\n",
    "            \n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "            \n",
    "            cv2.rectangle(\n",
    "                output,\n",
    "                (x - r, y - r - text_height - baseline - 10),\n",
    "                (x - r + text_width, y - r),\n",
    "                (0, 0, 255),\n",
    "                -1\n",
    "            )\n",
    "            \n",
    "            cv2.putText(\n",
    "                output,\n",
    "                label,\n",
    "                (x - r, y - r - 10),\n",
    "                font,\n",
    "                font_scale,\n",
    "                (255, 255, 255),\n",
    "                thickness\n",
    "            )\n",
    "            \n",
    "            results.append((gray_roi, th_roi, pred, confidence_scores, classes))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing coin {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return output, results\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 5B. DEBUGGING FUNCTION\n",
    "# =============================================\n",
    "def analyze_misclassification(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Analisis kesalahan klasifikasi untuk debugging\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALISIS KESALAHAN KLASIFIKASI\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    misclass_indices = np.where(y_test != y_pred)[0]\n",
    "    \n",
    "    if len(misclass_indices) == 0:\n",
    "        print(\"‚úÖ Tidak ada kesalahan klasifikasi! Perfect accuracy!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nTotal kesalahan: {len(misclass_indices)} dari {len(y_test)} ({len(misclass_indices)/len(y_test)*100:.1f}%)\")\n",
    "    print(\"\\nDetail kesalahan:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for idx in misclass_indices:\n",
    "        true_label = y_test[idx]\n",
    "        pred_label = y_pred[idx]\n",
    "        \n",
    "        decision_scores = model.decision_function([X_test[idx]])[0]\n",
    "        confidence_scores = np.exp(decision_scores) / np.sum(np.exp(decision_scores))\n",
    "        classes = model.classes_\n",
    "        \n",
    "        print(f\"\\nSample {idx}:\")\n",
    "        print(f\"  True label:      Rp {true_label}\")\n",
    "        print(f\"  Predicted label: Rp {pred_label}\")\n",
    "        print(f\"  Confidence scores:\")\n",
    "        \n",
    "        sorted_indices = np.argsort(confidence_scores)[::-1]\n",
    "        for i in sorted_indices:\n",
    "            print(f\"    Rp {classes[i]:4s}: {confidence_scores[i]*100:5.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PASANGAN YANG SERING SALAH\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    confusion_pairs = {}\n",
    "    for idx in misclass_indices:\n",
    "        pair = (y_test[idx], y_pred[idx])\n",
    "        confusion_pairs[pair] = confusion_pairs.get(pair, 0) + 1\n",
    "    \n",
    "    sorted_pairs = sorted(confusion_pairs.items(), key=lambda x: x[1], reverse=True)\n",
    "    for (true, pred), count in sorted_pairs:\n",
    "        print(f\"Rp {true} ‚Üí Rp {pred}: {count}x\")\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 5C. AUGMENTATION FUNCTION\n",
    "# =============================================\n",
    "def augment_data(X, y, augmentation_factor=3):\n",
    "    \"\"\"\n",
    "    Augmentasi data dengan transformasi sederhana\n",
    "    \"\"\"\n",
    "    print(f\"\\nMelakukan augmentasi data (factor={augmentation_factor})...\")\n",
    "    \n",
    "    X_aug = [X]\n",
    "    y_aug = [y]\n",
    "    \n",
    "    for i in range(augmentation_factor - 1):\n",
    "        noise = np.random.normal(0, 0.01, X.shape)\n",
    "        X_noisy = X + noise\n",
    "        \n",
    "        X_aug.append(X_noisy)\n",
    "        y_aug.append(y)\n",
    "    \n",
    "    X_final = np.vstack(X_aug)\n",
    "    y_final = np.hstack(y_aug)\n",
    "    \n",
    "    print(f\"Data sebelum augmentasi: {len(X)}\")\n",
    "    print(f\"Data setelah augmentasi: {len(X_final)}\")\n",
    "    \n",
    "    return X_final, y_final\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 5D. SAVE/LOAD MODEL\n",
    "# =============================================\n",
    "def save_model(model, filepath=\"coin_classifier_model.pkl\"):\n",
    "    \"\"\"Save trained model ke file\"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Model berhasil disimpan ke: {filepath}\")\n",
    "\n",
    "\n",
    "def load_model(filepath=\"coin_classifier_model.pkl\"):\n",
    "    \"\"\"Load trained model dari file\"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        return None\n",
    "    \n",
    "    with open(filepath, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Model berhasil dimuat dari: {filepath}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# 6. GRADIO INTERFACE\n",
    "# =============================================\n",
    "def create_gradio_interface(model):\n",
    "    \"\"\"Membuat Gradio interface untuk testing model\"\"\"\n",
    "    import gradio as gr\n",
    "    \n",
    "    def process_image(image, show_confidence):\n",
    "        if image is None:\n",
    "            return None, [], \"Tidak ada gambar yang diupload\"\n",
    "        \n",
    "        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        output, results = detect_and_predict(image_bgr, model, show_confidence=show_confidence)\n",
    "        output_rgb = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        gallery_images = []\n",
    "        predictions = []\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            gray_roi, th_roi, pred = result[0], result[1], result[2]\n",
    "            \n",
    "            gray_rgb = cv2.cvtColor(gray_roi, cv2.COLOR_GRAY2RGB)\n",
    "            th_rgb = cv2.cvtColor(th_roi, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "            gallery_images.append((gray_rgb, f\"Coin {i+1}: Grayscale\"))\n",
    "            gallery_images.append((th_rgb, f\"Coin {i+1}: Threshold\"))\n",
    "            \n",
    "            predictions.append(pred)\n",
    "        \n",
    "        if len(results) == 0:\n",
    "            summary = \"‚ùå Tidak ada koin terdeteksi\\n\\n\"\n",
    "            summary += \"Tips:\\n\"\n",
    "            summary += \"- Pastikan pencahayaan cukup\\n\"\n",
    "            summary += \"- Koin tidak terlalu berdekatan\\n\"\n",
    "            summary += \"- Background kontras dengan koin\"\n",
    "        else:\n",
    "            summary = f\"‚úÖ Terdeteksi {len(results)} koin\\n\\n\"\n",
    "            summary += \"Hasil Klasifikasi:\\n\"\n",
    "            summary += \"-\" * 40 + \"\\n\"\n",
    "            \n",
    "            for i, result in enumerate(results):\n",
    "                pred = result[2]\n",
    "                confidence_scores = result[3]\n",
    "                classes = result[4]\n",
    "                \n",
    "                if confidence_scores is not None and classes is not None:\n",
    "                    sorted_indices = np.argsort(confidence_scores)[::-1][:3]\n",
    "                    \n",
    "                    summary += f\"\\nKoin {i+1}: Rp {pred}\\n\"\n",
    "                    summary += \"  Top 3 predictions:\\n\"\n",
    "                    for idx in sorted_indices:\n",
    "                        summary += f\"    Rp {classes[idx]:4s}: {confidence_scores[idx]*100:5.1f}%\\n\"\n",
    "                else:\n",
    "                    summary += f\"Koin {i+1}: Rp {pred}\\n\"\n",
    "            \n",
    "            summary += \"\\n\" + \"=\" * 40 + \"\\n\"\n",
    "            \n",
    "            from collections import Counter\n",
    "            coin_counts = Counter(predictions)\n",
    "            \n",
    "            summary += \"\\nRingkasan:\\n\"\n",
    "            total_value = 0\n",
    "            for coin, count in sorted(coin_counts.items()):\n",
    "                coin_value = int(coin)\n",
    "                subtotal = coin_value * count\n",
    "                total_value += subtotal\n",
    "                summary += f\"- Rp {coin}: {count}x = Rp {subtotal:,}\\n\"\n",
    "            \n",
    "            summary += f\"\\nüí∞ TOTAL NILAI: Rp {total_value:,}\"\n",
    "        \n",
    "        return output_rgb, gallery_images, summary\n",
    "    \n",
    "    with gr.Blocks(title=\"Klasifikasi Koin Rupiah\", theme=gr.themes.Soft()) as demo:\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # ü™ô Klasifikasi Koin Rupiah\n",
    "            \n",
    "            Upload gambar koin Rupiah untuk deteksi dan klasifikasi otomatis.\n",
    "            \n",
    "            **Denominasi yang didukung:** Rp 100, Rp 200, Rp 500, Rp 1000\n",
    "            \n",
    "            **Metode:** Otsu Thresholding + HOG + Hu Moments + SVM Classifier\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                input_image = gr.Image(label=\"üì∑ Upload Gambar Koin\", type=\"numpy\")\n",
    "                \n",
    "                show_confidence = gr.Checkbox(\n",
    "                    label=\"Tampilkan Confidence Scores\",\n",
    "                    value=True,\n",
    "                    info=\"Menampilkan tingkat kepercayaan prediksi\"\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    clear_btn = gr.ClearButton(components=[input_image], value=\"üóëÔ∏è Clear\")\n",
    "                    submit_btn = gr.Button(\"üîç Detect & Classify\", variant=\"primary\")\n",
    "                \n",
    "                summary_output = gr.Textbox(label=\"üìä Ringkasan Hasil\", lines=15, interactive=False)\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                output_image = gr.Image(label=\"‚ú® Hasil Deteksi & Klasifikasi\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            gallery_output = gr.Gallery(\n",
    "                label=\"üî¨ Preprocessing Steps (Grayscale & Threshold)\",\n",
    "                columns=4,\n",
    "                height=\"auto\"\n",
    "            )\n",
    "        \n",
    "        submit_btn.click(\n",
    "            fn=process_image,\n",
    "            inputs=[input_image, show_confidence],\n",
    "            outputs=[output_image, gallery_output, summary_output]\n",
    "        )\n",
    "        \n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            ---\n",
    "            ### üí° Tips untuk Hasil Terbaik:\n",
    "            \n",
    "            1. **Pencahayaan**: Gunakan pencahayaan yang cukup dan merata\n",
    "            2. **Background**: Gunakan background yang kontras (gelap untuk koin terang)\n",
    "            3. **Jarak**: Hindari koin yang terlalu berdekatan atau bertumpuk\n",
    "            4. **Fokus**: Pastikan gambar tidak blur\n",
    "            5. **Sudut**: Foto dari atas tegak lurus dengan koin\n",
    "            \n",
    "            ### üîç Interpretasi Confidence Scores:\n",
    "            - **> 80%**: Prediksi sangat yakin ‚úÖ\n",
    "            - **60-80%**: Prediksi cukup yakin ‚ö†Ô∏è\n",
    "            - **< 60%**: Prediksi kurang yakin, mungkin perlu foto lebih baik ‚ùå\n",
    "            \n",
    "            ### üõ†Ô∏è Teknologi:\n",
    "            - **Preprocessing**: CLAHE, Otsu Thresholding, Morphological Operations\n",
    "            - **Feature Extraction**: \n",
    "              - HOG (Histogram of Oriented Gradients)\n",
    "              - Hu Moments (Shape descriptor)\n",
    "              - Texture Histogram\n",
    "              - Edge Density Analysis\n",
    "              - Circularity & Geometry features\n",
    "            - **Classifier**: Support Vector Machine (SVM) with RBF kernel\n",
    "            \"\"\"\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "\n",
    "# =============================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    import time\n",
    "    \n",
    "    overall_start = time.time()\n",
    "    \n",
    "    # KONFIGURASI\n",
    "    DATASET_PATH = \"dataset2\"\n",
    "    MODEL_PATH = \"coin_classifier_model.pkl\"\n",
    "    \n",
    "    # Set ini ke True jika ingin SKIP training dan langsung pakai model tersimpan\n",
    "    USE_SAVED_MODEL = False\n",
    "    \n",
    "    # Training settings\n",
    "    USE_AUGMENTATION = True\n",
    "    AUGMENTATION_FACTOR = 2\n",
    "    FAST_MODE = True  # True = cepat (~2 menit), False = akurat (~8 menit)\n",
    "    \n",
    "    # ==========================================\n",
    "    # 1. LOAD ATAU TRAIN MODEL\n",
    "    # ==========================================\n",
    "    \n",
    "    if USE_SAVED_MODEL:\n",
    "        print(\"=\"*60)\n",
    "        print(\"LOADING SAVED MODEL\")\n",
    "        print(\"=\"*60)\n",
    "        model = load_model(MODEL_PATH)\n",
    "        \n",
    "        if model is None:\n",
    "            print(\"‚ùå Model tidak ditemukan! Training model baru...\")\n",
    "            USE_SAVED_MODEL = False\n",
    "        else:\n",
    "            print(\"‚úÖ Menggunakan model tersimpan. Skip training.\")\n",
    "    \n",
    "    if not USE_SAVED_MODEL:\n",
    "        # Load dataset\n",
    "        print(\"=\"*60)\n",
    "        print(\"LOADING DATASET\")\n",
    "        print(\"=\"*60)\n",
    "        X, y, label_map = load_dataset(DATASET_PATH, use_side=False)\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            print(\"\\n‚ùå Error: Dataset kosong!\")\n",
    "            print(\"Pastikan path dataset benar dan folder berisi gambar.\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"DATA SPLIT (SEBELUM AUGMENTASI)\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"  Train: {len(X_train)}\")\n",
    "        print(f\"  Validation: {len(X_val)}\")\n",
    "        print(f\"  Test: {len(X_test)}\")\n",
    "        \n",
    "        # Augmentasi\n",
    "        if USE_AUGMENTATION:\n",
    "            X_train_aug, y_train_aug = augment_data(X_train, y_train, augmentation_factor=AUGMENTATION_FACTOR)\n",
    "            print(f\"\\nData training setelah augmentasi: {len(X_train_aug)}\")\n",
    "        else:\n",
    "            X_train_aug, y_train_aug = X_train, y_train\n",
    "        \n",
    "        # Train model\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"TRAINING MODEL\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        model = train_model(X_train_aug, y_train_aug, X_val, y_val, fast_mode=FAST_MODE)\n",
    "        \n",
    "        # Evaluate\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"EVALUATION ON TEST SET\")\n",
    "        print(\"=\"*60)\n",
    "        evaluate_model(model, X_test, y_test)\n",
    "        \n",
    "        # Analisis kesalahan\n",
    "        analyze_misclassification(model, X_test, y_test)\n",
    "        \n",
    "        # Save model\n",
    "        save_model(model, MODEL_PATH)\n",
    "        \n",
    "        overall_elapsed = time.time() - overall_start\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"‚è±Ô∏è  TOTAL WAKTU: {overall_elapsed:.1f} detik ({overall_elapsed/60:.1f} menit)\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # ==========================================\n",
    "    # 2. LAUNCH GRADIO\n",
    "    # ==========================================\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"LAUNCHING GRADIO INTERFACE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nüöÄ Starting Gradio interface...\")\n",
    "    print(\"üì± Open the URL in your browser to test the model\")\n",
    "    print(\"\\nüí° Tips:\")\n",
    "    print(\"   - Set USE_SAVED_MODEL = True untuk skip training di run berikutnya\")\n",
    "    print(\"   - Set FAST_MODE = True untuk training cepat (~2 menit)\")\n",
    "    print(\"   - Set FAST_MODE = False untuk akurasi maksimal (~8 menit)\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    demo = create_gradio_interface(model)\n",
    "    demo.launch(\n",
    "        share=False,  # Set to True if you want public link\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=6971\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
