{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ff0cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pustaka\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Konfigurasi Data ---\n",
    "# Ganti BASE_DIR dengan jalur ke folder 'dataset' Anda\n",
    "BASE_DIR = 'dataset/train' \n",
    "\n",
    "# Kelas koin yang akan diklasifikasikan (sesuai nama folder)\n",
    "CLASSES = ['50', '100', '200', '500', '1000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a1f66bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai pengumpulan dan ekstraksi fitur Momen Hu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Memproses 50: 100%|██████████| 28/28 [00:00<00:00, 305.73it/s]\n",
      "Memproses 100: 100%|██████████| 28/28 [00:00<00:00, 302.77it/s]\n",
      "Memproses 200: 100%|██████████| 28/28 [00:00<00:00, 271.68it/s]\n",
      "Memproses 500: 100%|██████████| 28/28 [00:00<00:00, 374.91it/s]\n",
      "Memproses 1000: 100%|██████████| 28/28 [00:00<00:00, 368.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ekstraksi fitur selesai.\n",
      "Total sampel yang diekstrak: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_hu_moments(image_path):\n",
    "    \"\"\"\n",
    "    Memuat gambar, melakukan pra-pemrosesan, dan mengekstrak Momen Invarian Hu.\n",
    "    \"\"\"\n",
    "    # 1. Muat Gambar dan Konversi ke Grayscale\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2. Pra-pemrosesan dan Segmentasi\n",
    "    # Gunakan Gaussian Blur untuk mengurangi noise\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Gunakan Thresholding Adaptif atau Otsu untuk mendapatkan gambar biner\n",
    "    # Otsu's Thresholding seringkali bagus untuk koin\n",
    "    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Optional: Erosi/Dilasi untuk membersihkan bintik kecil\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    # 3. Cari Kontur\n",
    "    # Diasumsikan kontur terbesar adalah koin itu sendiri\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if not contours:\n",
    "        return None\n",
    "    \n",
    "    # Ambil kontur terbesar\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # 4. Hitung Momen dan Momen Invarian Hu\n",
    "    moments = cv2.moments(largest_contour)\n",
    "    hu_moments = cv2.HuMoments(moments).flatten()\n",
    "    \n",
    "    # 5. Normalisasi Fitur (Log Transform)\n",
    "    # Log transform membantu menstabilkan nilai fitur, sering digunakan pada Momen Hu\n",
    "    # hu_moments_normalized = -np.sign(hu_moments) * np.log10(np.abs(hu_moments))\n",
    "    epsilon = 1e-12\n",
    "    hu_moments_normalized = -np.sign(hu_moments) * np.log10(np.abs(hu_moments) + epsilon)\n",
    "\n",
    "    if np.any(np.isnan(hu_moments_normalized)) or np.any(np.isinf(hu_moments_normalized)):\n",
    "        return None\n",
    "\n",
    "    return hu_moments_normalized\n",
    "\n",
    "# --- Proses Pengumpulan Data ---\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "print(\"Memulai pengumpulan dan ekstraksi fitur Momen Hu...\")\n",
    "\n",
    "for i, class_name in enumerate(CLASSES):\n",
    "    class_path = os.path.join(BASE_DIR, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path):\n",
    "        print(f\"Peringatan: Folder {class_path} tidak ditemukan. Melewati.\")\n",
    "        continue\n",
    "        \n",
    "    # Iterasi melalui setiap gambar di dalam folder kelas\n",
    "    image_files = [f for f in os.listdir(class_path) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "    \n",
    "    # Gunakan tqdm untuk menampilkan progress bar\n",
    "    for filename in tqdm(image_files, desc=f'Memproses {class_name}'):\n",
    "        image_path = os.path.join(class_path, filename)\n",
    "        \n",
    "        hu_features = extract_hu_moments(image_path)\n",
    "        \n",
    "        if hu_features is not None:\n",
    "            features.append(hu_features)\n",
    "            labels.append(class_name)\n",
    "\n",
    "print(\"\\nEkstraksi fitur selesai.\")\n",
    "print(f\"Total sampel yang diekstrak: {len(features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0690a55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah sampel pelatihan (Train): 112\n",
      "Jumlah sampel pengujian (Test): 28\n",
      "Training selesai!\n"
     ]
    }
   ],
   "source": [
    "# Konversi list ke numpy array\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Bagi data menjadi Training (80%) dan Testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y) # stratify memastikan pembagian kelas yang merata\n",
    "\n",
    "print(f\"Jumlah sampel pelatihan (Train): {len(X_train)}\")\n",
    "print(f\"Jumlah sampel pengujian (Test): {len(X_test)}\")\n",
    "\n",
    "# --- Training Model SVM ---\n",
    "model = SVC(kernel='rbf', C=10, gamma='scale')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c793988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Laporan Klasifikasi SVM ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          50       0.20      0.33      0.25         6\n",
      "         100       0.00      0.00      0.00         5\n",
      "         200       0.67      0.67      0.67         6\n",
      "         500       0.50      0.17      0.25         6\n",
      "        1000       0.56      1.00      0.71         5\n",
      "\n",
      "    accuracy                           0.43        28\n",
      "   macro avg       0.38      0.43      0.38        28\n",
      "weighted avg       0.39      0.43      0.38        28\n",
      "\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[1 3 1 1 0]\n",
      " [0 2 1 2 1]\n",
      " [0 2 4 0 0]\n",
      " [0 0 0 5 0]\n",
      " [1 3 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# --- Prediksi dan Evaluasi ---\n",
    "\n",
    "# Prediksi pada data pengujian\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Laporan Klasifikasi SVM ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=CLASSES))\n",
    "\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "# Confusion Matrix menunjukkan seberapa banyak prediksi yang benar vs salah per kelas\n",
    "cm = confusion_matrix(y_test, y_pred, labels=CLASSES)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "931f1a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model telah disimpan sebagai: svm_coin_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "# Import joblib untuk menyimpan model\n",
    "import joblib\n",
    "\n",
    "# Simpan model yang sudah dilatih (untuk digunakan nanti)\n",
    "MODEL_FILENAME = 'svm_coin_classifier.joblib'\n",
    "joblib.dump(model, MODEL_FILENAME)\n",
    "print(f\"\\nModel telah disimpan sebagai: {MODEL_FILENAME}\")\n",
    "\n",
    "# --- Simulasi Klasifikasi Gambar Baru ---\n",
    "\n",
    "# Anda bisa mengganti ini dengan path gambar koin baru dari user\n",
    "# new_coin_path = 'path/to/new/user/coin.jpg' \n",
    "# Anggap saja kita mengambil salah satu gambar dari set pengujian sebagai contoh:\n",
    "# Gunakan path gambar koin 500 sebagai contoh (Anda harus mendapatkan path gambar sebenarnya)\n",
    "# Contoh path:\n",
    "# example_new_coin_path = os.path.join(BASE_DIR, '500', 'contoh_koin_500.jpg')\n",
    "\n",
    "# --- Contoh Kode Klasifikasi ---\n",
    "def classify_new_coin(image_path, trained_model):\n",
    "    \"\"\"Melakukan prediksi pada gambar koin baru.\"\"\"\n",
    "    \n",
    "    # 1. Ekstrak fitur\n",
    "    new_features = extract_hu_moments(image_path)\n",
    "    \n",
    "    if new_features is None:\n",
    "        return \"Gagal memproses gambar (kontur tidak ditemukan).\"\n",
    "        \n",
    "    # 2. Ubah format menjadi array 2D (dibutuhkan oleh Scikit-learn)\n",
    "    new_features = new_features.reshape(1, -1)\n",
    "    \n",
    "    # 3. Prediksi\n",
    "    prediction = trained_model.predict(new_features)\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "# Memuat model yang disimpan\n",
    "# loaded_model = joblib.load(MODEL_FILENAME)\n",
    "\n",
    "# Lakukan prediksi (gunakan model 'model' yang masih ada di memori untuk demo)\n",
    "# KLASIFIKASI_HASIL = classify_new_coin(example_new_coin_path, model) \n",
    "# print(f\"\\nKoin baru diklasifikasikan sebagai: {KLASIFIKASI_HASIL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a05d245b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\queueing.py\", line 763, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\blocks.py\", line 2125, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\blocks.py\", line 1607, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\anyio\\to_thread.py\", line 61, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2525, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\utils.py\", line 1066, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_2748\\2942660705.py\", line 29, in detect_and_label\n",
      "    pred = model.predict(roi_resized)[0]\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 822, in predict\n",
      "    y = super().predict(X)\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 436, in predict\n",
      "    X = self._validate_for_predict(X)\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 614, in _validate_for_predict\n",
      "    X = validate_data(\n",
      "        self,\n",
      "    ...<5 lines>...\n",
      "        reset=False,\n",
      "    )\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2975, in validate_data\n",
      "    _check_n_features(_estimator, X, reset=reset)\n",
      "    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2839, in _check_n_features\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: X has 16384 features, but SVC is expecting 7 features as input.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def detect_and_label(img):\n",
    "  # convert PIL → OpenCV\n",
    "  img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  circles = cv2.HoughCircles(\n",
    "    gray,\n",
    "    cv2.HOUGH_GRADIENT,\n",
    "    dp=1,\n",
    "    minDist=50,\n",
    "    param1=100,\n",
    "    param2=30,\n",
    "    minRadius=20,\n",
    "    maxRadius=200\n",
    "  )\n",
    "\n",
    "  output = img.copy()\n",
    "\n",
    "  if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for (x, y, r) in circles[0, :]:\n",
    "      roi = gray[y-r:y+r, x-r:x+r]\n",
    "      if roi.size == 0:\n",
    "        continue\n",
    "\n",
    "      roi_resized = cv2.resize(roi, (128,128)).flatten().reshape(1, -1)\n",
    "      pred = model.predict(roi_resized)[0]\n",
    "\n",
    "      cv2.circle(output, (x, y), r, (0, 0, 255), 3)\n",
    "      cv2.putText(output, str(pred), (x - 20, y - r - 10),\n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "  output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "  return output\n",
    "\n",
    "\n",
    "gr.Interface(\n",
    "  fn=detect_and_label,\n",
    "  inputs=gr.Image(type=\"pil\", label=\"Upload Foto Koin\"),\n",
    "  outputs=gr.Image(type=\"numpy\", label=\"Hasil Deteksi\"),\n",
    "  title=\"Klasifikasi Koin Rupiah\",\n",
    "  description=\"Upload gambar koin, sistem akan mendeteksi dan memberi label nominal.\"\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
